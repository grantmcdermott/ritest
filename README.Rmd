---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# ritest

<!-- badges: start -->
[![R-CMD-check](https://github.com/grantmcdermott/ritest/workflows/R-CMD-check/badge.svg)](https://github.com/grantmcdermott/ritest/actions)
<!-- badges: end -->

An experimental R port of the **[`ritest`](https://github.com/simonheb)** Stata 
routine for randomization inference by [Simon HeÃŸ](https://github.com/simonheb). 

Fast and user-friendly. Currently limited to `lm()` and `fixest::feols()` 
models, but aims to support a variety of model classes once it is fully baked.

## Installation

``` r
# install.packages("remotes")
remotes::install_github("grantmcdermott/ritest")
```

Note that **ritest** currently depends on the development version (0.10.0) of
**fixest**. If you're on 
[Windows](https://cran.r-project.org/bin/windows/Rtools/) or 
[Mac](https://github.com/rmacoslib/r-macos-rtools#how-do-i-use-the-installer) 
then you'll need _Rtools_ for compiling the underlying C++ code before running
the above command. (Click on the relevant link to install.)

## Examples

First, load the **ritest** package. 
I'll also load the **fixest** and **haven** packages to help demonstrate some
additional functionality in the examples that follow.

```{r libs, cache=FALSE, message=FALSE}
library(ritest)
library(fixest) ## Note: ritest requires fixest version >= 0.10.0
library(haven)  ## For reading .dta files
```

### Toy data

Here's a naive example using the inbuilt
[`nkp`](https://vincentarelbundock.github.io/Rdatasets/doc/MASS/npk.html) 
dataset.

```{r est}
est = lm(yield ~ N + P + K, data = npk)
```

Conduct RI on the 'N' (i.e. nitrogen) coefficient. We'll do 1,000 simulations
and, just for illustration, limit the number of parallel cores to 2. 
(The default parallel behaviour will use half of the available cores on a user's
machine.) 
The 'verbose = TRUE' argument simply prints the results upon completion,
including the original regression model summary.

```{r est_ri}
# est_ri = ritest(est, ~N, reps = 1e3, seed = 1234L, pcores = 2L, verbose = TRUE) ## Formulas work too
est_ri = ritest(est, 'N', reps = 1e3, seed = 1234L, pcores = 2L, verbose = TRUE)
```

We can also visualize the result using the default `plot` method. This function 
takes several arguments for added customization. But here I'll just show how to
add the parametric 95 percent confidence interval (i.e. from the original linear 
regression) in addition the simulated rejection regions.

```{r plot_est_ri}
plot(est_ri, show_parm = TRUE)
```

A more realistic implementation would control for the stratified (aka "blocked")
experimental design. We'll specify these strata (blocks) as fixed-effects in 
our regression model. Again, we obtain an RI ejection rate (0.003) that is very 
similar to the parametric p-value (0.004) from the regression model.

```{r est2}
# library(fixest) ## Already loaded

est2 = feols(yield ~ N + P + K | block, vcov = 'iid', data = npk)

# Re-do our RI from before, but this time permute within the 'block' strata.
# ritest(est2, ~N, strata = ~block, reps = 1e3, seed = 99L) ## Again, formulas work
ritest(est2, 'N', strata = 'block', reps = 1e3, seed = 99L)
```

### Real-life data

Next, we'll replicate an example in David McKenzie's nice 
[blog post](https://blogs.worldbank.org/impactevaluations/finally-way-do-easy-randomization-inference-stata)
about the Stata `ritest` routine. The dataset in question derives from a 
randomized control trial about supply chains, which was conducted in Columbia. 
You can download the data from David's website 
[here](https://drive.google.com/open?id=0B9C9RwWKZrUNazdyVXFkSTlTNGc) (also 
includes code and data for some other examples.)

#### Stata implementation

First, here is the Stata code and output. I won't go into detail about the 
actual research question that we're trying to address. (See David's blog post 
for more on that.) However, the essential thing to know is that I'm going to run 
5,000 RI permutations on a pretty standard fixed-effect model, _whilst_ 
accounting for the stratified and clustered design of the experiment. 

(Aside: I'm also snipping most of the Stata output so as too only highlight the 
main command and result.)

```stata
. use "~/Colombia13.dta", clear

. 
. timer on 1

. 
. ritest b_treat _b[b_treat], cluster(b_block) strata(b_pair) reps(5e3) seed(546): ///
> areg dayscorab b_treat b_dayscorab miss_b_dayscorab round2 round3, cluster(b_block) a(b_pair)

[snipped]


      command:  areg dayscorab b_treat b_dayscorab miss_b_dayscorab round2 round3, cluster(b_block)
                    a(b_pair)
        _pm_1:  _b[b_treat]
  res. var(s):  b_treat
   Resampling:  Permuting b_treat
Clust. var(s):  b_block
     Clusters:  63
Strata var(s):  b_pair
       Strata:  31

------------------------------------------------------------------------------
T            |     T(obs)       c       n   p=c/n   SE(p) [95% Conf. Interval]
-------------+----------------------------------------------------------------
       _pm_1 |   -.180738     529    5000  0.1058  0.0043  .0974064   .1146569
------------------------------------------------------------------------------
Note: Confidence interval is with respect to p=c/n.
Note: c = #{|T| >= |T(obs)|}

. 
. timer off 1

```

Like David, this takes around **3 minutes** to run on my laptop.

```stata
. timer list
   1:    183.01 /        1 =     183.0150
```

#### R implementation

Now, the R equivalent with this package.

```{r co_ri}
## Load the data
co = haven::read_dta('~/clusterColombia.dta')

co_est = 
  feols(
    dayscorab ~ b_treat + b_dayscorab + miss_b_dayscorab + round2 + round3 | b_pair, 
    cluster = ~b_block,        
    data = co
    )

tic = Sys.time()
co_ri = ritest(co_est, ~b_treat, cluster=~b_block, strata=~b_pair, reps=5e3, seed=546L)
toc = Sys.time() - tic

## Print the results
co_ri
```

Using the same random seed is a bit of performance art. We won't get exactly
the same results across two different languages. But the important thing to note 
is that they are _functionally_ equivalent (rejection probability of 0.106 vs
0.104).

One nice feature of this implementation is that it should complete very quickly. 
This time, the 5,000 simulations only take around **6 seconds**.

```{r toc}
toc
```

Again, we can plot the results. Here's a slight variation, where we plot in
histogram form and use a fill to highlight the 95% rejection region(s) instead
of vertical lines.

```{r plot_co_ri}
plot(co_ri, type = 'hist', highlight = 'fill')
```


### Benchmarks

As indicated in the real-life data example, I generally observe a speed increase
of around 30x compared to the Stata version. This gap appears to widen further
for larger datasets and for certain kinds of RI setups.
